# Achieve Better Price to Performance up to 31% for Milvus on AWS with Graviton3 Processors

<picture>
 <img alt="YOUR-ALT-TEXT" src="assets/milvus_brand.png">
</picture>

<sub> _ AWS post by Xueyao Bai & Quan Yuan & Wantao Wu, Solution Architect _ <sub>

The popularity of generative AI (Generative AI) has aroused widespread attention and completely ignited the vector database market. 

According to IDC's forecast, by 2025, more than 80% of business data will be unstructured, stored in text, image, audio, video or other formats. However, storing and querying unstructured data on a large scale is a very big challenge.

The common practice in the field of generative AI and deep learning is to store unstructured data by converting it into vectors, and to search for semantic relevance through vector similarity search (Vector similarity search) technology. Fast storage, indexing and searching of Embedding vectors are the core functions of vector databases.

## About Milvus

Milvus was created in 2019 with a singular goal: store, index, and manage massive embedding vectors generated by deep neural networks and other machine learning (ML) models.
As a database specifically designed to handle queries over input vectors, it is capable of indexing vectors on a trillion scale. Unlike existing relational databases which mainly deal with structured data following a pre-defined pattern, Milvus is designed from the bottom-up to handle embedding vectors converted from unstructured data.
Currently, Milvus has gathered over 26k Stars in Github.

## About AWS Graviton
AWS Graviton processors are designed by AWS to deliver the best price performance for your cloud workloads running in Amazon EC2.

AWS Graviton3 processors are the latest in the AWS Graviton processor family which are already GA (Graviton4 is in Preview). They provide up to 25% better compute performance, up to 2x higher floating-point performance, and up to 2x faster cryptographic workload performance compared to AWS Graviton2 processors. AWS Graviton3 processors deliver up to 3x better performance compared to AWS Graviton2 processors for ML workloads, including support for bfloat16. They also support DDR5 memory that provides 50% more memory bandwidth compared to DDR4. AWS Graviton3E processors deliver up to 35% higher vector-instruction performance compared to AWS Graviton3 processors. This improvement provides higher performance benefits for HPC applications.

## Benchmark Description&Goal

To better understand what Graviton3 can bring to self-hosted Milvus, we will perform load test against Intel Xeon Platinum 8375C. 
Specific details is shown in below table:

<picture>
 <img alt="YOUR-ALT-TEXT" src="assets/ec2_type.png">
</picture>

<sub> _Graviton3 (m7g) VS Intel Xeon Platinum 8375C (m6i)_ <sub>
* OS and Storages:
    * AMI：Amazon Linux 2023 AMI(latest version)
    * EBS：GP3, 80GB(keep default performance level, Throughput 125MB/s, IOPS 3000)


### Benchmark Tools & Dataset Introduction

We are using VectorDBBench to perform test. VectorDBBench is a go-to tool for the ultimate performance and cost-effectiveness comparison. Designed with ease-of-use in mind, VectorDBBench is devised to help users, even non-professionals, reproduce results or test new systems, making the hunt for the optimal choice amongst a plethora of cloud services and open-source vector databases a breeze.

We are using Cohere https://huggingface.co/datasets/Cohere/wikipedia-22-12/tree/main/en as testing dataset.

### Methodology

We use the HNSW algorithm to index the Cohere 1M dataset. The HNSW (Hierarchical Navigable Small World) algorithm is an approximate nearest neighbor (ANN) algorithm used for indexing and searching high-dimensional data. It aims to address the challenges of fast nearest neighbor search in high-dimensional spaces where traditional exact k-nearest neighbors algorithm are inefficient. HNSW  algorithm has several parameters that you can configure to customize its behavior.  

* M: This parameter controls the maximum number of connections a data point can have in the hierarchical graph. 
* **fConstruction**: It stands for "ef Construction," and it controls the size of the dynamic list during the construction of the graph.
* **efSearch**: This parameter is used during the search phase and controls the size of the dynamic list while searching for nearest neighbors. A larger efSearch value can lead to a more exhaustive search but also increases query time.

In our tests, we select the same parameters for both ARM64 and X86 platforms. 

In this bench, we will compare the performance on x86 platform and the latest ARM one for Milvus 2.3.2.



### Milvus Installation

* Logon SUT EC2 instance above with SSH session separately.
* Perform following commands to setup Milvus 2.3.2 benchmark environment:

```
sudo su - root

## Install Docker and docker-compose
dnf install -y docker git htop
systemctl start docker
ARCH=$(arch)
curl -SL https://github.com/docker/compose/releases/download/v2.12.2/docker-compose-linux-${ARCH} \
     -o ./docker-compose
chmod +x docker-compose
mv docker-compose /usr/bin/

## Start milvus container
mkdir ~/milvus
cd ~/milvus
wget https://github.com/milvus-io/milvus/releases/download/v2.3.2/milvus-standalone-docker-compose.yml \
  -O docker-compose.yml
docker-compose up -d
docker-compose ps

```

After above steps, you should get Milvus v2.3.2 running on both instances. 
### VectorDBBench installation

We will install VectorDBBench on LoadGen instance, follow below steps to complete.

```
sudo su - root

## Need isntall Python 3.11 or above
dnf install -y python3.11 python3.11-pip python3.11-devel git gcc gcc-c++
python3.11 -V

## Install VectorDBBench
pip3.11 install vectordb-bench
which init_bench

## Redirect /tmp/vectordb_bench to another location
mkdir -p /mnt/vectordb_bench
ln -s /mnt/vectordb_bench /tmp/vectordb_bench

## init benchmark tool，follow the prompt to enter web page
init_bench
```
<picture>
 <img alt="YOUR-ALT-TEXT" src="assets/benchmark_install.png">
</picture>

Visit VectorDBBench Web Console via External URL, make sure you have allowed port 8501 in security group and allow the traffic in your VPC.

<picture>
 <img alt="YOUR-ALT-TEXT" src="assets/benchmark_webui.png">
</picture>

### Peform loadtest

* Press 【Run Your Test >】button to enter benchmark configurations, follow the instruction shown below to configure the benchmark tool.

<picture>
 <img alt="YOUR-ALT-TEXT" src="assets/run_benchmark1.png">
</picture>

<picture>
 <img alt="YOUR-ALT-TEXT" src="assets/run_benchmark2.png">
</picture>

<picture>
 <img alt="YOUR-ALT-TEXT" src="assets/run_benchmark3.png">
</picture>


### Explore Result 

* After all bechmark tests complete, you can find result via VectorDBBench WebUI

<picture>
 <img alt="YOUR-ALT-TEXT" src="assets/result.png">
</picture>

### Performance Comparison between Intel & Graviton3 instances

After above test running against m6i (Intel) m7g(Graviton3), we have final result as below:

<picture>
 <img alt="YOUR-ALT-TEXT" src="assets/compare.png">
</picture>

## Summary

Our test shows that general performance of Milvus on Graviton3 (m7g) achieve better QPS (13.7%) than Intel Xeon Platinum 8375C (m6i). 
Take the price into consideration, our result shows Graviton3 can bring up to 31% (m6i is 17.6% more expensive than m7g instance) increase compare to x86 processors on m6i series instance.

We encourage readers to try Graviton3 whenever possible and feel the pricing to performance improvement on Graviton3.

## Reference
* VDBBench https://github.com/zilliztech/VectorDBBench
* Cohere https://huggingface.co/datasets/Cohere/wikipedia-22-12/tree/main/en
* AWS EC2 Pricing https://aws.amazon.com/ec2/pricing/on-demand/

